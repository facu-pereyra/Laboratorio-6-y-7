#Este es un código escrito en python escrito para el procesamiento de audios adquiridos con una grabadora-reproductor en un espacio rural

#Como se trabajó en google.collaboratoy es necesario instalar las librerías:

!pip install wave

!pip install soundfile

!pip install noisereduce

#Se importan librerías necesarias:

import numpy as np
import matplotlib.pyplot as plt
from scipy.fft import rfft, rfftfreq # solo la parte real
import scipy.signal as sg
import glob
import librosa #librería alternativa para trabajar con audios
import IPython.display as ipd
from scipy.io import wavfile
import os
import warnings
import wave, struct
import IPython
import noisereduce as nr
import soundfile as sf
from noisereduce.generate_noise import band_limited_noise
import urllib.request
import io
import seaborn as sns
import parselmouth
%matplotlib inline

#Se importan N archivos *.WAV del drive:

os.chdir('/content/drive/MyDrive/Laboratorio 6 7/Labo 7/Analisis sonido /chingolo')

path="/content/drive/MyDrive/Laboratorio 6 7/Labo 7/Analisis sonido /chingolo"
path_nuevo="/content/drive/MyDrive/Laboratorio 6 7/Labo 7/Analisis sonido /Sonido_pajaros_filtrado"

files = os.listdir(path)
audio = sorted([i for i in files if i.endswith('.WAV')]) #VER PORQUE NO ANDA OR .wav
print(audio)

#Se definen funciones que se van a usar:

def leer_wav(archivo):
    warnings.filterwarnings("ignore")
    fs, data = wavfile.read(archivo)
    length = data.shape[0] / fs
    time = np.linspace(0, length, data.shape[0], endpoint=False)
    #print(f"tiempo: {time}") #tiempo
    #print(f"data: {data}") #intensidad de sonido
    #print(f"Cantidad de muestras: {1/(time[1]-time[0])} Hz") #frecuencia
    #print(f"Duración: {time[-1]+time[1]} s") #duración
    #print(f"tamaño tiempo: {time.shape}")
    #print(f"tamaño: {data.shape}")#cantidad de datos
    #print(f"dtype: {data.dtype}")#formato de dato(?)
    #print("**********************************************************")
    return time, fs, data

def print_info(time, data):
    print(f"tiempo: {time}")
    print(f"data: {data}") 
    print(f"Cantidad de muestras: {1/(time[1]-time[0])} Hz")
    print(f"Duración: {time[-1]+time[1]} s")
    print(f"tamaño: {data.shape}")
    print(f"dtype: {data.dtype}")
    print("**********************************************************")

def graficar_segundos (time, señal, fs, audio, contador):
    x = time
    plt.plot(x, señal, label=audio[contador])
    plt.xlabel('Tiempo [s]')
    plt.ylabel('Amplitud [ua]')
    plt.legend(loc='best')
    plt.tight_layout()
    plt.grid(color='g', linestyle='--', linewidth=0.2)
    plt.show()


def espectrograma(señal,fs):
    #https://matplotlib.org/3.1.1/gallery/color/colormap_reference.html
    plt.figure(figsize=(8, 2))
    #plt.specgram(señal, NFFT=int(fs*0.005), Fs=fs, cmap=plt.cm.gray, pad_to=256, noverlap=int(fs*0.0025))
    plt.specgram(señal, NFFT= 512 , Fs=fs, noverlap = 256 ,cmap='jet', mode='magnitude') #detrend='mean'
    plt.xlabel('Tiempo [s]')
    plt.ylabel('Frecuencia [Hz]')
    plt.ylim([0,fs/4])
    plt.tight_layout()
   # plt.grid(color='g', linestyle='--', linewidth=0.2)
    plt.show()

def espectrograma_nuevo(señal,fs, audio):
    plt.figure()
    f, t, Sxx = sg.spectrogram(señal, fs, nperseg=1024, noverlap=1020, scaling='spectrum')
    Sxx = np.clip(Sxx, a_min=np.amax(Sxx)/600, a_max=np.amax(Sxx))

    plt.pcolormesh(t,f,np.log10(Sxx), rasterized=True, cmap=plt.get_cmap('Greys'), shading='auto')
    plt.ylim(2000,8000)
    plt.minorticks_on()
    #plt.axis('off')
    #plt.grid(True)
    #plt.savefig('sonograma_{}.jpeg'.format(audio[:-4]), dpi=600, facecolor='w', edgecolor='w',
                #orientation='portrait', format=None,
                #transparent=False, bbox_inches=None, pad_inches=0.1) 
    plt.show()
    #plt.close('all')

def draw_spectrogram(spectrogram, dynamic_range=70):
    X, Y = spectrogram.x_grid(), spectrogram.y_grid()
    sg_db = 10 * np.log10(spectrogram.values)
    plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap='afmhot')
    plt.ylim([spectrogram.ymin, spectrogram.ymax])
    plt.xlabel("time [s]")
    plt.ylabel("frequency [Hz]")

def draw_intensity(intensity):
    plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color='w')
    plt.plot(intensity.xs(), intensity.values.T, linewidth=1)
    plt.grid(False)
    plt.ylim(0)
    plt.ylabel("intensity [dB]")

def graficar_FFT(señal,fs):
    fig, (ax1, ax2) = plt.subplots(2, 1)
    fig.suptitle('Transformada de Fourier')
    X = np.fft.rfft(señal)
    freqs = np.arange(len(X)) / len(señal) * fs
    #ax1.semilogx(freqs, pra.dB(X)) Consultar pra
    ax1.semilogx(freqs, X)
    ax1.set_ylabel("Amplitud [dB]")    
    ax1.grid(color='g', linestyle='--', linewidth=0.2)   
    yf = rfft(normalizar(señal))
    xf = rfftfreq(len(señal), 1 /fs) 
    ax2.semilogx(xf, np.abs(yf))
    ax2.set_xlabel("Frecuencia [Hz]")
    ax2.set_ylabel("Amplitud ua")
    ax2.grid(color='g', linestyle='--', linewidth=0.2)
    freq_pico = xf[np.argmax(np.abs(yf))]
    f, t, Zxx = sg.stft(señal, fs)
    plt.pcolormesh(t, f, np.abs(Zxx), shading='auto')
    plt.title('Magnitud STFT')
    plt.ylabel('Frecuencia [Hz]')
    plt.xlabel('Tiempo [sec]')
    plt.ylim([0,int(freq_pico)*4])
    plt.show()
    return freq_pico

def normalizar(señal):
    a = señal - np.mean(señal)
    a = a / np.std(a)
    señal_norm = a/max(a)
    return señal_norm

def filtro_pa (señal, fs, N, fc):
    sos = sg.butter(N, fc / (fs / 2), 'highpass', output='sos')
    señal_fil = sg.sosfiltfilt(sos, señal)
    return señal_fil

def filtro_pb (señal, fs, N, fc):
    sos = sg.butter(N, fc / (fs / 2), 'low', output='sos')
    señal_fil = sg.sosfiltfilt(sos, señal)
    return señal_fil

def ruido_mediana(señal, fs):
    señal_fil = sg.medfilt(señal,3)
    return señal_fil

def filtro_ruido (señal, fs):
  reduced_noise = nr.reduce_noise(y = señal, sr=fs, n_std_thresh_stationary=1.5,stationary=True)
  #fig, ax = plt.subplots(figsize=(20,3))
  #ax.plot(reduced_noise)
  return reduced_noise

def general_2 (path, audio, a, b,c, d): 
    time, fs, data = leer_wav(os.path.join(".", audio)) #Más de un fichero
    #filename = path + audio #Para un fichero
    #fs, data = leer_wav(filename) #Para un fichero
    norm = normalizar(data)
    señal_fil = filtro_pa (norm, fs, a, b)
    norm = normalizar(señal_fil)
    señal_fil = filtro_pb (norm, fs, c, d)
    a_norm = normalizar(señal_fil)
    señal_fil=ruido_mediana(a_norm,fs) 
    a_norm = normalizar(señal_fil)
    reduced_noise = filtro_ruido(a_norm, fs)

    return reduced_noise, fs,time

def write_file(output_file_path, input_file_name, name_attribute, sig, fs):

    fname = input_file_name[:8] + name_attribute + '.wav'
    fpath = os.path.join(output_file_path, fname)
    wavfile.write(filename=fpath, rate=fs, data=sig)
    print("Writing data to " + fpath + ".") 

def ventanas_señal(señal, tamaño_ventana):
    lista_vent_señal = np.array_split(señal, round(len(señal)/tamaño_ventana))
    return lista_vent_señal

def ventanas_tiempo_señal(señal, segundos, fs):
    lista_vent_tiempo_señal = np.array_split(señal, round(len(señal)/(segundos*fs)))
    return lista_vent_tiempo_señal

def cut_file(señal, ti, tf, fs):
     ### Sección específica del fichero en segundos ###
     señal_recortada = señal[int(ti*fs):int(tf*fs)]
     return señal_recortada

#Analisis de audios completos:

T = {}
M = {}

for j in range(len(audio)):
    key = j
    value, fs, time = general_2(path,str(audio[j]), 15, 1000, 15, 8000)
    M[key] = value 
    T[key] = time 
    
    
T_sf = {}
M_sf = {}

for i in range(len(audio)):
    key = i
    time, fs, value = leer_wav(audio[i]) #Me devuelve señal sin filtrar ni normalizar, frecuencia de muestreo
    M_sf[key] = value #Guardo lista de valores sin ningún filtro
    T_sf[key] = time #Guardo lista de tiempos
    
for contador in M:
    plt.figure(figsize=(8, 2))
    graficar_segundos (T_sf[contador], M_sf[contador], fs, audio, contador)
del audio, files,i,contador,key,value


for contador in M:
    plt.figure(figsize=(8, 2))
    graficar_segundos (T[contador], M[contador], fs, audio, contador)
del audio, files, j,contador,key,value


#Guardo archivos procesados en nueva carpeta:

fichero_nuevo = []
for contador in range(len(M)):
  new = write_file(path_nuevo, str(audio[contador]), "_filtrado", M[contador], fs)
  fichero_nuevo.append(new)
  
#Hago análisis por bloques:
#WARNING: Esta celda puede hacer que colapse la memoria RAM en google.collaboratory para muchos archivos

#Cuidado con correr colapsa RAM 

v = []
t = []

for i in range(len(M)):
  for contador in range(len(M)):
    v_contador = ventanas_señal(M[contador], 2200000) #Acá estoy tomando intervalos de 100 segundos
    t_contador = ventanas_tiempo_señal(T[contador], 100, fs)
    v.append(v_contador)
    t.append(t_contador)
  block_señal_i = v[i]
  block_tiempo_i = t[i]
  plt.figure(figsize=(8, 2))
  plt.plot(block_tiempo_i, block_señal_i)
  
#Hago el análisis por bloques para un archivo individual 


v_1 = ventanas_tiempo_señal(M[0], 10, fs)
t_1 = ventanas_tiempo_señal(T[0], 10, fs)


for i in range(len(v_1)):
  plt.figure()
  plt.plot(t_1[i], v_1[i])
  
#Se elije el bloque de interés: 

cut = cut_file(M[0], 25, 35, fs)
plt.plot(cut)
IPython.display.Audio(data=cut, rate=fs)

#Se crean espectrogramas de color para ese bloque:

spectro = espectrograma(cut,fs)

#Se crean especrtogramas blanco y negro para ese bloque:

spectro_nuevo = espectrograma_nuevo(cut,fs, audio[0])

#Se grafican picos de frecuencia:

graficar_FFT(cut,fs)
